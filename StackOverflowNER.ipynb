{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "StackOverflowNER.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/desis123/3aransia/blob/master/StackOverflowNER.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o14uJPpCdTpM"
      },
      "source": [
        "This is a replication of the paper [Code and Named Entity Recognizer for StackOverflow](https://www.aclweb.org/anthology/2020.acl-main.443.pdf)\n",
        "\n",
        "Their code and setup instructions can be found at https://github.com/jeniyat/StackOverflowNER\n",
        "\n",
        "The required resources to run this code can be found at https://drive.google.com/drive/folders/1iEEMr2DYofulK2F5pSErOPf5ggrEqtJt?usp=sharing\n",
        "\n",
        "Use \"Make a copy\" feature of google drive to copy the resources to your own drive. Put the resources under `/StackOverflowNER` folder.\n",
        "\n",
        "Prequisites:\n",
        "\n",
        "\n",
        "1.   Colab Pro subscription (for 200 GB Disk space)\n",
        "2.   Google drive subscription (200 GB)\n",
        "3.   Choose GPU + High Ram runtimes on colab\n",
        "\n",
        "\n",
        "\n",
        "You will need to complete the following steps:\n",
        "\n",
        "\n",
        "1.   Move `data_ctc.zip` to `/StackOverflowNER` (in the Google drive root folder)\n",
        "2.   Move `utils_fine_tune.tar.gz` to `/StackOverflowNER`\n",
        "3.   Move `fasttext.bin` to `/StackOverflowNER`\n",
        "4.   ~~Checkpoints from copied from [here](https://drive.google.com/drive/folders/1z4zXexpYU10QNlpcSA_UPfMb2V34zHHO) to /StackOverflowNER/BERTOverflow~~ This notebook downloads the pretrained BERT model from '[jeniya/BERTOverflow](https://huggingface.co/jeniya/BERTOverflow)'\n",
        "5.   ~~Make a copy of `/StackOverflowNER/StackOverflowNER/code/BERT_NER/utils_fine_tune/freq_embeds.npy` to `/StackOverflowNER/StackOverflowNER/code/BERT_NER/`~~ \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bDIXkjfNd-HO",
        "outputId": "7f53c7ec-93ac-41a2-8e9d-1577d13c76b5"
      },
      "source": [
        "# Run everytime\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive') # mount gdrive, where files are stored\n",
        "\n",
        "drive_path_prefix = '/content/drive/MyDrive/StackOverflowNER/' # Path to google drive folder\n",
        "\n",
        "SOPath = os.path.join(drive_path_prefix, 'StackOverflowNER')\n",
        "print(SOPath)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/StackOverflowNER/StackOverflowNER\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9DQJFar7RCw"
      },
      "source": [
        "# RUN ONLY ONCE\n",
        "# Download and install modified HuggingFace Transformer\n",
        "%cd $drive_path_prefix\n",
        "!git clone https://github.com/jeniyat/Attentive_Transformer_NER.git\n",
        "\n",
        "# Clone StackOverflowNER repo\n",
        "!git clone https://github.com/zen93/StackOverflowNER.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLumJoo18llu"
      },
      "source": [
        "#RUN ONLY ONCE; EXTRACTED FILES ARE PERMANENTLY STORED IN DRIVE\n",
        "import tarfile\n",
        "\n",
        "data_ctc_path = os.path.join(drive_path_prefix, 'data_ctc.zip')\n",
        "\n",
        "!unzip $data_ctc_path\n",
        "\n",
        "utils_fine_tune_path = os.path.join(drive_path_prefix, 'utils_fine_tune.tar.gz')\n",
        "utils_fine_tune_dest_path = os.path.join(drive_path_prefix, 'StackOverflowNER/code/BERT_NER')\n",
        "\n",
        "!tar -xvzf $utils_fine_tune_path -C $utils_fine_tune_dest_path\n",
        "\n",
        "freq_embeds_extracted_path = os.path.join(utils_fine_tune_dest_path, 'utils_fine_tune', 'freq_embeds.npy')\n",
        "freq_embeds_new_path = utils_fine_tune_dest_path\n",
        "\n",
        "!cp $freq_embeds_extracted_path $freq_embeds_new_path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HyQZ_Qjhcflc",
        "outputId": "dd072f61-aff5-497e-99fb-269379be031a"
      },
      "source": [
        "# To update the StackOverflowNER repository from remote\n",
        "SOPath = os.path.join(drive_path_prefix, 'StackOverflowNER')\n",
        "%cd $SOPath\n",
        "!git pull\n",
        "%cd .."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/StackOverflowNER/StackOverflowNER\n",
            "Already up to date.\n",
            "/content/drive/MyDrive/StackOverflowNER\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9Pb5mk2ivzC",
        "outputId": "f68d72c2-415f-42cd-a597-07efeb3f2c47"
      },
      "source": [
        "# RUN EVERYTIME\n",
        "# Install required prerequsites\n",
        "# Install modified HuggingFace Transformer\n",
        "ATN_Path = os.path.join(drive_path_prefix, 'Attentive_Transformer_NER')\n",
        "\n",
        "%cd $ATN_Path\n",
        "!pip install . # Install transformer library\n",
        "%cd ..\n",
        "\n",
        "!pip install ftfy\n",
        "!pip install https://github.com/kpu/kenlm/archive/master.zip\n",
        "!pip install fasttext\n",
        "!pip install seqeval"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/StackOverflowNER/Attentive_Transformer_NER\n",
            "Processing /content/drive/MyDrive/StackOverflowNER/Attentive_Transformer_NER\n",
            "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
            "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (1.19.5)\n",
            "Collecting tokenizers==0.7.0\n",
            "  Downloading tokenizers-0.7.0-cp37-cp37m-manylinux1_x86_64.whl (5.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6 MB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (4.62.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (2019.12.20)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 38.6 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 69.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.8.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.8.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.8.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.8.0) (2021.5.30)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.8.0) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.8.0) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.8.0) (1.0.1)\n",
            "Building wheels for collected packages: transformers\n",
            "  Building wheel for transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-2.8.0-py3-none-any.whl size=600924 sha256=9b07b509e5419bc704122d60b2b3789c3644b5d7eaf787d4feaf8dafa33d18aa\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-o3jgez7t/wheels/90/15/e3/a77d466782e5842cd17ef39d61a60444c0ac3efbcaad016f25\n",
            "Successfully built transformers\n",
            "Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.45 sentencepiece-0.1.96 tokenizers-0.7.0 transformers-2.8.0\n",
            "/content/drive/MyDrive/StackOverflowNER\n",
            "Collecting ftfy\n",
            "  Downloading ftfy-6.0.3.tar.gz (64 kB)\n",
            "\u001b[K     |████████████████████████████████| 64 kB 2.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from ftfy) (0.2.5)\n",
            "Building wheels for collected packages: ftfy\n",
            "  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ftfy: filename=ftfy-6.0.3-py3-none-any.whl size=41933 sha256=047296e713f8b6397597a5d47d7ac1f83d3143fc2a6bd12a9ace3d0394b931d6\n",
            "  Stored in directory: /root/.cache/pip/wheels/19/f5/38/273eb3b5e76dfd850619312f693716ac4518b498f5ffb6f56d\n",
            "Successfully built ftfy\n",
            "Installing collected packages: ftfy\n",
            "Successfully installed ftfy-6.0.3\n",
            "Collecting https://github.com/kpu/kenlm/archive/master.zip\n",
            "  Downloading https://github.com/kpu/kenlm/archive/master.zip (540 kB)\n",
            "\u001b[K     |████████████████████████████████| 540 kB 1.3 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: kenlm\n",
            "  Building wheel for kenlm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kenlm: filename=kenlm-0.0.0-cp37-cp37m-linux_x86_64.whl size=2334961 sha256=301f4f8c11c4646e7abc48de5f7d8d90b79651b190b7ccc4f7c999f2185226f4\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-0n7gkjl_/wheels/3d/aa/02/7b4a2eab5d7a2a9391bd9680dbad6270808a147bc3b7047e4e\n",
            "Successfully built kenlm\n",
            "Installing collected packages: kenlm\n",
            "Successfully installed kenlm-0.0.0\n",
            "Collecting fasttext\n",
            "  Downloading fasttext-0.9.2.tar.gz (68 kB)\n",
            "\u001b[K     |████████████████████████████████| 68 kB 3.7 MB/s \n",
            "\u001b[?25hCollecting pybind11>=2.2\n",
            "  Using cached pybind11-2.7.1-py2.py3-none-any.whl (200 kB)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from fasttext) (57.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fasttext) (1.19.5)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.2-cp37-cp37m-linux_x86_64.whl size=3096929 sha256=4cc5790966ecb139ec3d270896152b05f201eaf0ca8a05dc807bce29869b9d05\n",
            "  Stored in directory: /root/.cache/pip/wheels/4e/ca/bf/b020d2be95f7641801a6597a29c8f4f19e38f9c02a345bab9b\n",
            "Successfully built fasttext\n",
            "Installing collected packages: pybind11, fasttext\n",
            "Successfully installed fasttext-0.9.2 pybind11-2.7.1\n",
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[K     |████████████████████████████████| 43 kB 1.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.0.1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.1)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16181 sha256=d997a9e17173b5aac1530a839a47e5501d06b757bab54d8dd1a364080774fde6\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n",
            "Successfully built seqeval\n",
            "Installing collected packages: seqeval\n",
            "Successfully installed seqeval-1.2.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XKH-te2cbRuo",
        "outputId": "d83829ac-0c66-4ded-84f5-acc8b97db4db"
      },
      "source": [
        "E2E_SoftNER = os.path.join(SOPath, 'code/BERT_NER/E2E_SoftNER.py')\n",
        "data = os.path.join(SOPath, 'code/BERT_NER/xml_filted_body.txt')\n",
        "\n",
        "!python $E2E_SoftNER \\\n",
        "--input_file_with_so_body $data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/StackOverflowNER/StackOverflowNER/code/BERT_NER/E2E_SoftNER.py\", line 3, in <module>\n",
            "    from utils_preprocess.anntoconll import *\n",
            "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
            "  File \"<frozen importlib._bootstrap>\", line 967, in _find_and_load_unlocked\n",
            "  File \"<frozen importlib._bootstrap>\", line 677, in _load_unlocked\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 724, in exec_module\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 818, in get_code\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 917, in get_data\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2fYpFR1Cgoi",
        "outputId": "897c5753-237c-4f3d-b0ee-77f0dba7d493"
      },
      "source": [
        "# DEBUGGING\n",
        "WORKING_DIR = '/content/drive/MyDrive/StackOverflowNER/StackOverflowNER/code/BERT_NER'\n",
        "%cd $WORKING_DIR\n",
        "# E2E_new = os.path.join(SOPath, 'code/BERT_NER/E2E_new.py')\n",
        "# data = os.path.join(SOPath, 'code/BERT_NER/xml_filted_body.txt')\n",
        "\n",
        "E2E_new = './E2E_new.py'\n",
        "data = './xml_filted_body.txt'\n",
        "print(\"From jupyter:\", E2E_new, data)\n",
        "\n",
        "!python $E2E_new \\\n",
        "--input_file_with_so_body $data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/StackOverflowNER/StackOverflowNER/code/BERT_NER\n",
            "From jupyter: ./E2E_new.py ./xml_filted_body.txt\n",
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
            "tcmalloc: large alloc 4408983552 bytes == 0x561e00128000 @  0x7fd7ac71b887 0x7fd714dd1683 0x7fd714dd6c4f 0x7fd714dd7261 0x7fd714d96ce3 0x7fd714dbc0f1 0x561dd32dcbf8 0x561dd33506f2 0x561dd334ac35 0x561dd32ddfec 0x561dd331ebc9 0x561dd331bac4 0x561dd32dc8a9 0x561dd3350b0a 0x561dd32dd65a 0x561dd334ff40 0x561dd334ac35 0x561dd334a933 0x561dd3348c9b 0x561dd33f19c2 0x561dd32de34a 0x561dd335180f 0x561dd334ac35 0x561dd32dd73a 0x561dd334ff40 0x561dd32dd65a 0x561dd334bd67 0x561dd32dd65a 0x561dd334bb0e 0x561dd32dd65a 0x561dd334bb0e\n",
            "tcmalloc: large alloc 2008981504 bytes == 0x561f06de4000 @  0x7fd7ac71b887 0x7fd714dd1683 0x7fd714dd6c9e 0x7fd714dd7261 0x7fd714d96ce3 0x7fd714dbc0f1 0x561dd32dcbf8 0x561dd33506f2 0x561dd334ac35 0x561dd32ddfec 0x561dd331ebc9 0x561dd331bac4 0x561dd32dc8a9 0x561dd3350b0a 0x561dd32dd65a 0x561dd334ff40 0x561dd334ac35 0x561dd334a933 0x561dd3348c9b 0x561dd33f19c2 0x561dd32de34a 0x561dd335180f 0x561dd334ac35 0x561dd32dd73a 0x561dd334ff40 0x561dd32dd65a 0x561dd334bd67 0x561dd32dd65a 0x561dd334bb0e 0x561dd32dd65a 0x561dd334bb0e\n",
            "2021-08-17 14:53:27.270962: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "./xml_filted_body.txt\n",
            "[0.428365932464601, 0.19701098799705508, 0.29119153594970726, 0.01899447679519639, 0.002]\n",
            "temp_files/standoff_files/\n",
            "08/17/2021 14:57:28 - INFO - filelock -   Lock 140560253902288 acquired on /root/.cache/torch/transformers/142616a02e9dc91c33dea71980a0b0a30293e9148a24200461db5a9a1d14cc08.9989c9b6c815ffeeb8371cbf069c97e290c68345d13de5c494dd0cc8378bb6a2.lock\n",
            "08/17/2021 14:57:28 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/jeniya/BERTOverflow/config.json not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmp1hw6djp4\n",
            "Downloading: 100% 3.24k/3.24k [00:00<00:00, 3.93MB/s]\n",
            "08/17/2021 14:57:28 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/jeniya/BERTOverflow/config.json in cache at /root/.cache/torch/transformers/142616a02e9dc91c33dea71980a0b0a30293e9148a24200461db5a9a1d14cc08.9989c9b6c815ffeeb8371cbf069c97e290c68345d13de5c494dd0cc8378bb6a2\n",
            "08/17/2021 14:57:28 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/142616a02e9dc91c33dea71980a0b0a30293e9148a24200461db5a9a1d14cc08.9989c9b6c815ffeeb8371cbf069c97e290c68345d13de5c494dd0cc8378bb6a2\n",
            "08/17/2021 14:57:28 - INFO - filelock -   Lock 140560253902288 released on /root/.cache/torch/transformers/142616a02e9dc91c33dea71980a0b0a30293e9148a24200461db5a9a1d14cc08.9989c9b6c815ffeeb8371cbf069c97e290c68345d13de5c494dd0cc8378bb6a2.lock\n",
            "08/17/2021 14:57:28 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/jeniya/BERTOverflow/config.json from cache at /root/.cache/torch/transformers/142616a02e9dc91c33dea71980a0b0a30293e9148a24200461db5a9a1d14cc08.9989c9b6c815ffeeb8371cbf069c97e290c68345d13de5c494dd0cc8378bb6a2\n",
            "08/17/2021 14:57:28 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/jeniya/BERTOverflow/config.json from cache at /root/.cache/torch/transformers/142616a02e9dc91c33dea71980a0b0a30293e9148a24200461db5a9a1d14cc08.9989c9b6c815ffeeb8371cbf069c97e290c68345d13de5c494dd0cc8378bb6a2\n",
            "08/17/2021 14:57:28 - INFO - transformers.tokenization_utils -   Model name 'jeniya/BERTOverflow' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'jeniya/BERTOverflow' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
            "08/17/2021 14:57:28 - INFO - filelock -   Lock 140560253857872 acquired on /root/.cache/torch/transformers/366ae98d80f3b62a08f76a38479c158b649841fd881ff16b7743c6cd02e631bc.57407c8df6c9d1057e13023df5979b60098b4ddabccd9eaa0bb483a48778f8ff.lock\n",
            "08/17/2021 14:57:28 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/jeniya/BERTOverflow/vocab.txt not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpqebjssev\n",
            "Downloading: 100% 660k/660k [00:00<00:00, 4.68MB/s]\n",
            "08/17/2021 14:57:28 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/jeniya/BERTOverflow/vocab.txt in cache at /root/.cache/torch/transformers/366ae98d80f3b62a08f76a38479c158b649841fd881ff16b7743c6cd02e631bc.57407c8df6c9d1057e13023df5979b60098b4ddabccd9eaa0bb483a48778f8ff\n",
            "08/17/2021 14:57:28 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/366ae98d80f3b62a08f76a38479c158b649841fd881ff16b7743c6cd02e631bc.57407c8df6c9d1057e13023df5979b60098b4ddabccd9eaa0bb483a48778f8ff\n",
            "08/17/2021 14:57:28 - INFO - filelock -   Lock 140560253857872 released on /root/.cache/torch/transformers/366ae98d80f3b62a08f76a38479c158b649841fd881ff16b7743c6cd02e631bc.57407c8df6c9d1057e13023df5979b60098b4ddabccd9eaa0bb483a48778f8ff.lock\n",
            "08/17/2021 14:57:29 - INFO - filelock -   Lock 140560253860112 acquired on /root/.cache/torch/transformers/a48a990c12709e78145491ae4164de040c423ba56ad84bb065c5b790b70e979c.1f04d662a14dbb60dcf1073d308fd370f7244f21fee819dd5627fb5afeb761b1.lock\n",
            "08/17/2021 14:57:29 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/jeniya/BERTOverflow/special_tokens_map.json not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpehzci65r\n",
            "Downloading: 100% 156/156 [00:00<00:00, 221kB/s]\n",
            "08/17/2021 14:57:29 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/jeniya/BERTOverflow/special_tokens_map.json in cache at /root/.cache/torch/transformers/a48a990c12709e78145491ae4164de040c423ba56ad84bb065c5b790b70e979c.1f04d662a14dbb60dcf1073d308fd370f7244f21fee819dd5627fb5afeb761b1\n",
            "08/17/2021 14:57:29 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/a48a990c12709e78145491ae4164de040c423ba56ad84bb065c5b790b70e979c.1f04d662a14dbb60dcf1073d308fd370f7244f21fee819dd5627fb5afeb761b1\n",
            "08/17/2021 14:57:29 - INFO - filelock -   Lock 140560253860112 released on /root/.cache/torch/transformers/a48a990c12709e78145491ae4164de040c423ba56ad84bb065c5b790b70e979c.1f04d662a14dbb60dcf1073d308fd370f7244f21fee819dd5627fb5afeb761b1.lock\n",
            "08/17/2021 14:57:29 - INFO - filelock -   Lock 140560253885968 acquired on /root/.cache/torch/transformers/584c0fa64a417a840bbf15614dc921abe67c1a1ad7b24a4e286384304d047dfc.6d3e4821752052e0ae3af7835326d4262263e6de3587c25295702a3dc40ba072.lock\n",
            "08/17/2021 14:57:29 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/jeniya/BERTOverflow/tokenizer_config.json not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpvqxh79lb\n",
            "Downloading: 100% 42.0/42.0 [00:00<00:00, 42.9kB/s]\n",
            "08/17/2021 14:57:29 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/jeniya/BERTOverflow/tokenizer_config.json in cache at /root/.cache/torch/transformers/584c0fa64a417a840bbf15614dc921abe67c1a1ad7b24a4e286384304d047dfc.6d3e4821752052e0ae3af7835326d4262263e6de3587c25295702a3dc40ba072\n",
            "08/17/2021 14:57:29 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/584c0fa64a417a840bbf15614dc921abe67c1a1ad7b24a4e286384304d047dfc.6d3e4821752052e0ae3af7835326d4262263e6de3587c25295702a3dc40ba072\n",
            "08/17/2021 14:57:29 - INFO - filelock -   Lock 140560253885968 released on /root/.cache/torch/transformers/584c0fa64a417a840bbf15614dc921abe67c1a1ad7b24a4e286384304d047dfc.6d3e4821752052e0ae3af7835326d4262263e6de3587c25295702a3dc40ba072.lock\n",
            "08/17/2021 14:57:29 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/jeniya/BERTOverflow/vocab.txt from cache at /root/.cache/torch/transformers/366ae98d80f3b62a08f76a38479c158b649841fd881ff16b7743c6cd02e631bc.57407c8df6c9d1057e13023df5979b60098b4ddabccd9eaa0bb483a48778f8ff\n",
            "08/17/2021 14:57:29 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/jeniya/BERTOverflow/added_tokens.json from cache at None\n",
            "08/17/2021 14:57:29 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/jeniya/BERTOverflow/special_tokens_map.json from cache at /root/.cache/torch/transformers/a48a990c12709e78145491ae4164de040c423ba56ad84bb065c5b790b70e979c.1f04d662a14dbb60dcf1073d308fd370f7244f21fee819dd5627fb5afeb761b1\n",
            "08/17/2021 14:57:29 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/jeniya/BERTOverflow/tokenizer_config.json from cache at /root/.cache/torch/transformers/584c0fa64a417a840bbf15614dc921abe67c1a1ad7b24a4e286384304d047dfc.6d3e4821752052e0ae3af7835326d4262263e6de3587c25295702a3dc40ba072\n",
            "08/17/2021 14:57:30 - INFO - filelock -   Lock 140563234383952 acquired on /root/.cache/torch/transformers/4ed2423d9e63e71e4105cc22e6dbcb8bc4797612653f5c8cc38d1c9954c76229.2fa1917386056883053a04ed5d44adf1f1dc1cd20881a810ffb522ef3c47cee2.lock\n",
            "08/17/2021 14:57:30 - INFO - transformers.file_utils -   https://cdn.huggingface.co/jeniya/BERTOverflow/pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpo74podvc\n",
            "Downloading: 100% 596M/596M [00:09<00:00, 63.8MB/s]\n",
            "08/17/2021 14:57:39 - INFO - transformers.file_utils -   storing https://cdn.huggingface.co/jeniya/BERTOverflow/pytorch_model.bin in cache at /root/.cache/torch/transformers/4ed2423d9e63e71e4105cc22e6dbcb8bc4797612653f5c8cc38d1c9954c76229.2fa1917386056883053a04ed5d44adf1f1dc1cd20881a810ffb522ef3c47cee2\n",
            "08/17/2021 14:57:39 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/4ed2423d9e63e71e4105cc22e6dbcb8bc4797612653f5c8cc38d1c9954c76229.2fa1917386056883053a04ed5d44adf1f1dc1cd20881a810ffb522ef3c47cee2\n",
            "08/17/2021 14:57:39 - INFO - filelock -   Lock 140563234383952 released on /root/.cache/torch/transformers/4ed2423d9e63e71e4105cc22e6dbcb8bc4797612653f5c8cc38d1c9954c76229.2fa1917386056883053a04ed5d44adf1f1dc1cd20881a810ffb522ef3c47cee2.lock\n",
            "08/17/2021 14:57:39 - INFO - transformers.modeling_utils -   loading weights file https://cdn.huggingface.co/jeniya/BERTOverflow/pytorch_model.bin from cache at /root/.cache/torch/transformers/4ed2423d9e63e71e4105cc22e6dbcb8bc4797612653f5c8cc38d1c9954c76229.2fa1917386056883053a04ed5d44adf1f1dc1cd20881a810ffb522ef3c47cee2\n",
            "08/17/2021 14:57:43 - INFO - softner_segmenter_preditct_from_file -   Parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', data_dir='/content/drive/MyDrive/StackOverflowNER/StackOverflowNER/code/BERT_NER/utils_fine_tune/ip_seg/', device=device(type='cuda'), do_eval=False, do_lower_case=False, do_predict=False, do_train=False, eval_all_checkpoints=False, evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, input_file_for_segmenter='/content/drive/MyDrive/StackOverflowNER/StackOverflowNER/code/BERT_NER/utils_fine_tune/ip_seg/dev.txt', keep_accents=None, labels='/content/drive/MyDrive/StackOverflowNER/StackOverflowNER/code/BERT_NER/utils_fine_tune/labels_so.txt', learning_rate=5e-05, local_rank=-1, logging_steps=500, max_grad_norm=1.0, max_seq_length=128, max_steps=-1, model_name_or_path='jeniya/BERTOverflow', model_type='bert', n_gpu=1, no_cuda=False, num_train_epochs=5, output_dir='jeniya/BERTOverflow', output_file_for_segmenter='segemeter_preds.txt', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=8, per_gpu_train_batch_size=4, save_steps=500, seed=1, server_ip='', server_port='', strip_accents=None, tokenizer_name='', use_fast=None, warmup_steps=0, weight_decay=0.0)\n",
            "08/17/2021 14:57:44 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/jeniya/BERTOverflow/config.json from cache at /root/.cache/torch/transformers/142616a02e9dc91c33dea71980a0b0a30293e9148a24200461db5a9a1d14cc08.9989c9b6c815ffeeb8371cbf069c97e290c68345d13de5c494dd0cc8378bb6a2\n",
            "08/17/2021 14:57:44 - INFO - transformers.tokenization_utils -   Model name 'jeniya/BERTOverflow' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'jeniya/BERTOverflow' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
            "08/17/2021 14:57:44 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/jeniya/BERTOverflow/vocab.txt from cache at /root/.cache/torch/transformers/366ae98d80f3b62a08f76a38479c158b649841fd881ff16b7743c6cd02e631bc.57407c8df6c9d1057e13023df5979b60098b4ddabccd9eaa0bb483a48778f8ff\n",
            "08/17/2021 14:57:44 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/jeniya/BERTOverflow/added_tokens.json from cache at None\n",
            "08/17/2021 14:57:44 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/jeniya/BERTOverflow/special_tokens_map.json from cache at /root/.cache/torch/transformers/a48a990c12709e78145491ae4164de040c423ba56ad84bb065c5b790b70e979c.1f04d662a14dbb60dcf1073d308fd370f7244f21fee819dd5627fb5afeb761b1\n",
            "08/17/2021 14:57:44 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/jeniya/BERTOverflow/tokenizer_config.json from cache at /root/.cache/torch/transformers/584c0fa64a417a840bbf15614dc921abe67c1a1ad7b24a4e286384304d047dfc.6d3e4821752052e0ae3af7835326d4262263e6de3587c25295702a3dc40ba072\n",
            "08/17/2021 14:57:44 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/jeniya/BERTOverflow/config.json from cache at /root/.cache/torch/transformers/142616a02e9dc91c33dea71980a0b0a30293e9148a24200461db5a9a1d14cc08.9989c9b6c815ffeeb8371cbf069c97e290c68345d13de5c494dd0cc8378bb6a2\n",
            "08/17/2021 14:57:45 - INFO - transformers.modeling_utils -   loading weights file https://cdn.huggingface.co/jeniya/BERTOverflow/pytorch_model.bin from cache at /root/.cache/torch/transformers/4ed2423d9e63e71e4105cc22e6dbcb8bc4797612653f5c8cc38d1c9954c76229.2fa1917386056883053a04ed5d44adf1f1dc1cd20881a810ffb522ef3c47cee2\n",
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "08/17/2021 14:57:50 - INFO - transformers.configuration_utils -   loading configuration file ./utils_fine_tune/word_piece_ner/config.json\n",
            "08/17/2021 14:57:50 - INFO - transformers.configuration_utils -   loading configuration file ./utils_fine_tune/word_piece_ner/config.json\n",
            "08/17/2021 14:57:50 - INFO - transformers.tokenization_utils -   Model name './utils_fine_tune/word_piece_ner/' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming './utils_fine_tune/word_piece_ner/' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
            "08/17/2021 14:57:50 - INFO - transformers.tokenization_utils -   Didn't find file ./utils_fine_tune/word_piece_ner/added_tokens.json. We won't load it.\n",
            "08/17/2021 14:57:50 - INFO - transformers.tokenization_utils -   Didn't find file ./utils_fine_tune/word_piece_ner/special_tokens_map.json. We won't load it.\n",
            "08/17/2021 14:57:50 - INFO - transformers.tokenization_utils -   Didn't find file ./utils_fine_tune/word_piece_ner/tokenizer_config.json. We won't load it.\n",
            "08/17/2021 14:57:50 - INFO - transformers.tokenization_utils -   loading file ./utils_fine_tune/word_piece_ner/vocab.txt\n",
            "08/17/2021 14:57:50 - INFO - transformers.tokenization_utils -   loading file None\n",
            "08/17/2021 14:57:50 - INFO - transformers.tokenization_utils -   loading file None\n",
            "08/17/2021 14:57:50 - INFO - transformers.tokenization_utils -   loading file None\n",
            "08/17/2021 14:57:50 - INFO - transformers.modeling_utils -   loading weights file ./utils_fine_tune/word_piece_ner/pytorch_model.bin\n",
            "08/17/2021 14:57:57 - INFO - softner_ner_predict_from_file -   Parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', data_dir='./utils_fine_tune/ip_ner/', device=device(type='cuda'), do_eval=True, do_lower_case=False, do_predict=True, do_train=False, eval_all_checkpoints=False, evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, input_file_for_ner='./utils_fine_tune/dev.txt', keep_accents=None, labels='./utils_fine_tune/labels_so.txt', learning_rate=5e-05, local_rank=-1, logging_steps=500, max_grad_norm=1.0, max_seq_length=128, max_steps=-1, model_name_or_path='./utils_fine_tune/word_piece_ner/', model_type='bert', n_gpu=1, no_cuda=False, num_train_epochs=5.0, output_dir='./utils_fine_tune/bert-word-piece-softner/', output_file_for_ner='ner_preds.txt', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=8, per_gpu_train_batch_size=4, save_steps=500, seed=0, server_ip='', server_port='', strip_accents=None, tokenizer_name='', use_fast=None, warmup_steps=0, weight_decay=0.0)\n",
            "08/17/2021 14:57:57 - INFO - transformers.configuration_utils -   loading configuration file ./utils_fine_tune/bert-word-piece-softner/config.json\n",
            "08/17/2021 14:57:57 - INFO - transformers.tokenization_utils -   Model name './utils_fine_tune/bert-word-piece-softner/' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming './utils_fine_tune/bert-word-piece-softner/' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
            "08/17/2021 14:57:57 - INFO - transformers.tokenization_utils -   Didn't find file ./utils_fine_tune/bert-word-piece-softner/added_tokens.json. We won't load it.\n",
            "08/17/2021 14:57:57 - INFO - transformers.tokenization_utils -   loading file ./utils_fine_tune/bert-word-piece-softner/vocab.txt\n",
            "08/17/2021 14:57:57 - INFO - transformers.tokenization_utils -   loading file None\n",
            "08/17/2021 14:57:57 - INFO - transformers.tokenization_utils -   loading file ./utils_fine_tune/bert-word-piece-softner/special_tokens_map.json\n",
            "08/17/2021 14:57:57 - INFO - transformers.tokenization_utils -   loading file ./utils_fine_tune/bert-word-piece-softner/tokenizer_config.json\n",
            "08/17/2021 14:57:58 - INFO - transformers.configuration_utils -   loading configuration file ./utils_fine_tune/bert-word-piece-softner/config.json\n",
            "08/17/2021 14:57:58 - INFO - transformers.modeling_utils -   loading weights file ./utils_fine_tune/bert-word-piece-softner/pytorch_model.bin\n",
            "\n",
            "\n",
            "\n",
            "-------------------------------------------------------------------------------------------------\n",
            "***** Perdictions on sentences is stored at  ner_preds.txt *****\n",
            "-------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XOHC5MuCPa5",
        "outputId": "41d9ac7d-e04f-4113-eac8-47b14a52b5c4"
      },
      "source": [
        "# IGNORE --TESTING/TROUBLESHOOTING--\n",
        "WORKING_DIR = '/content/drive/MyDrive/StackOverflowNER/StackOverflowNER/code/BERT_NER'\n",
        "%cd $WORKING_DIR\n",
        "!python test.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/StackOverflowNER/StackOverflowNER/code/BERT_NER\n",
            "2021-08-09 08:10:13.328072: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "08/09/2021 08:10:15 - INFO - filelock -   Lock 140265070802832 acquired on /root/.cache/torch/transformers/142616a02e9dc91c33dea71980a0b0a30293e9148a24200461db5a9a1d14cc08.9989c9b6c815ffeeb8371cbf069c97e290c68345d13de5c494dd0cc8378bb6a2.lock\n",
            "08/09/2021 08:10:15 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/jeniya/BERTOverflow/config.json not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpzyc3f54m\n",
            "Downloading: 100% 3.24k/3.24k [00:00<00:00, 3.62MB/s]\n",
            "08/09/2021 08:10:15 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/jeniya/BERTOverflow/config.json in cache at /root/.cache/torch/transformers/142616a02e9dc91c33dea71980a0b0a30293e9148a24200461db5a9a1d14cc08.9989c9b6c815ffeeb8371cbf069c97e290c68345d13de5c494dd0cc8378bb6a2\n",
            "08/09/2021 08:10:15 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/142616a02e9dc91c33dea71980a0b0a30293e9148a24200461db5a9a1d14cc08.9989c9b6c815ffeeb8371cbf069c97e290c68345d13de5c494dd0cc8378bb6a2\n",
            "08/09/2021 08:10:15 - INFO - filelock -   Lock 140265070802832 released on /root/.cache/torch/transformers/142616a02e9dc91c33dea71980a0b0a30293e9148a24200461db5a9a1d14cc08.9989c9b6c815ffeeb8371cbf069c97e290c68345d13de5c494dd0cc8378bb6a2.lock\n",
            "08/09/2021 08:10:15 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/jeniya/BERTOverflow/config.json from cache at /root/.cache/torch/transformers/142616a02e9dc91c33dea71980a0b0a30293e9148a24200461db5a9a1d14cc08.9989c9b6c815ffeeb8371cbf069c97e290c68345d13de5c494dd0cc8378bb6a2\n",
            "08/09/2021 08:10:16 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/jeniya/BERTOverflow/config.json from cache at /root/.cache/torch/transformers/142616a02e9dc91c33dea71980a0b0a30293e9148a24200461db5a9a1d14cc08.9989c9b6c815ffeeb8371cbf069c97e290c68345d13de5c494dd0cc8378bb6a2\n",
            "08/09/2021 08:10:16 - INFO - transformers.tokenization_utils -   Model name 'jeniya/BERTOverflow' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'jeniya/BERTOverflow' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
            "08/09/2021 08:10:16 - INFO - filelock -   Lock 140265070771280 acquired on /root/.cache/torch/transformers/366ae98d80f3b62a08f76a38479c158b649841fd881ff16b7743c6cd02e631bc.57407c8df6c9d1057e13023df5979b60098b4ddabccd9eaa0bb483a48778f8ff.lock\n",
            "08/09/2021 08:10:16 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/jeniya/BERTOverflow/vocab.txt not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpw8nwjvi2\n",
            "Downloading: 100% 660k/660k [00:00<00:00, 1.95MB/s]\n",
            "08/09/2021 08:10:17 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/jeniya/BERTOverflow/vocab.txt in cache at /root/.cache/torch/transformers/366ae98d80f3b62a08f76a38479c158b649841fd881ff16b7743c6cd02e631bc.57407c8df6c9d1057e13023df5979b60098b4ddabccd9eaa0bb483a48778f8ff\n",
            "08/09/2021 08:10:17 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/366ae98d80f3b62a08f76a38479c158b649841fd881ff16b7743c6cd02e631bc.57407c8df6c9d1057e13023df5979b60098b4ddabccd9eaa0bb483a48778f8ff\n",
            "08/09/2021 08:10:17 - INFO - filelock -   Lock 140265070771280 released on /root/.cache/torch/transformers/366ae98d80f3b62a08f76a38479c158b649841fd881ff16b7743c6cd02e631bc.57407c8df6c9d1057e13023df5979b60098b4ddabccd9eaa0bb483a48778f8ff.lock\n",
            "08/09/2021 08:10:17 - INFO - filelock -   Lock 140265063906064 acquired on /root/.cache/torch/transformers/a48a990c12709e78145491ae4164de040c423ba56ad84bb065c5b790b70e979c.1f04d662a14dbb60dcf1073d308fd370f7244f21fee819dd5627fb5afeb761b1.lock\n",
            "08/09/2021 08:10:17 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/jeniya/BERTOverflow/special_tokens_map.json not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpeno1v0oi\n",
            "Downloading: 100% 156/156 [00:00<00:00, 163kB/s]\n",
            "08/09/2021 08:10:18 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/jeniya/BERTOverflow/special_tokens_map.json in cache at /root/.cache/torch/transformers/a48a990c12709e78145491ae4164de040c423ba56ad84bb065c5b790b70e979c.1f04d662a14dbb60dcf1073d308fd370f7244f21fee819dd5627fb5afeb761b1\n",
            "08/09/2021 08:10:18 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/a48a990c12709e78145491ae4164de040c423ba56ad84bb065c5b790b70e979c.1f04d662a14dbb60dcf1073d308fd370f7244f21fee819dd5627fb5afeb761b1\n",
            "08/09/2021 08:10:18 - INFO - filelock -   Lock 140265063906064 released on /root/.cache/torch/transformers/a48a990c12709e78145491ae4164de040c423ba56ad84bb065c5b790b70e979c.1f04d662a14dbb60dcf1073d308fd370f7244f21fee819dd5627fb5afeb761b1.lock\n",
            "08/09/2021 08:10:18 - INFO - filelock -   Lock 140265070772112 acquired on /root/.cache/torch/transformers/584c0fa64a417a840bbf15614dc921abe67c1a1ad7b24a4e286384304d047dfc.6d3e4821752052e0ae3af7835326d4262263e6de3587c25295702a3dc40ba072.lock\n",
            "08/09/2021 08:10:18 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/jeniya/BERTOverflow/tokenizer_config.json not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpxl6gt7ze\n",
            "Downloading: 100% 42.0/42.0 [00:00<00:00, 48.2kB/s]\n",
            "08/09/2021 08:10:18 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/jeniya/BERTOverflow/tokenizer_config.json in cache at /root/.cache/torch/transformers/584c0fa64a417a840bbf15614dc921abe67c1a1ad7b24a4e286384304d047dfc.6d3e4821752052e0ae3af7835326d4262263e6de3587c25295702a3dc40ba072\n",
            "08/09/2021 08:10:18 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/584c0fa64a417a840bbf15614dc921abe67c1a1ad7b24a4e286384304d047dfc.6d3e4821752052e0ae3af7835326d4262263e6de3587c25295702a3dc40ba072\n",
            "08/09/2021 08:10:18 - INFO - filelock -   Lock 140265070772112 released on /root/.cache/torch/transformers/584c0fa64a417a840bbf15614dc921abe67c1a1ad7b24a4e286384304d047dfc.6d3e4821752052e0ae3af7835326d4262263e6de3587c25295702a3dc40ba072.lock\n",
            "08/09/2021 08:10:18 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/jeniya/BERTOverflow/vocab.txt from cache at /root/.cache/torch/transformers/366ae98d80f3b62a08f76a38479c158b649841fd881ff16b7743c6cd02e631bc.57407c8df6c9d1057e13023df5979b60098b4ddabccd9eaa0bb483a48778f8ff\n",
            "08/09/2021 08:10:18 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/jeniya/BERTOverflow/added_tokens.json from cache at None\n",
            "08/09/2021 08:10:18 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/jeniya/BERTOverflow/special_tokens_map.json from cache at /root/.cache/torch/transformers/a48a990c12709e78145491ae4164de040c423ba56ad84bb065c5b790b70e979c.1f04d662a14dbb60dcf1073d308fd370f7244f21fee819dd5627fb5afeb761b1\n",
            "08/09/2021 08:10:18 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/jeniya/BERTOverflow/tokenizer_config.json from cache at /root/.cache/torch/transformers/584c0fa64a417a840bbf15614dc921abe67c1a1ad7b24a4e286384304d047dfc.6d3e4821752052e0ae3af7835326d4262263e6de3587c25295702a3dc40ba072\n",
            "08/09/2021 08:10:19 - INFO - filelock -   Lock 140265070802832 acquired on /root/.cache/torch/transformers/4ed2423d9e63e71e4105cc22e6dbcb8bc4797612653f5c8cc38d1c9954c76229.2fa1917386056883053a04ed5d44adf1f1dc1cd20881a810ffb522ef3c47cee2.lock\n",
            "08/09/2021 08:10:19 - INFO - transformers.file_utils -   https://cdn.huggingface.co/jeniya/BERTOverflow/pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpfwj54gu6\n",
            "Downloading: 100% 596M/596M [00:14<00:00, 39.7MB/s]\n",
            "08/09/2021 08:10:34 - INFO - transformers.file_utils -   storing https://cdn.huggingface.co/jeniya/BERTOverflow/pytorch_model.bin in cache at /root/.cache/torch/transformers/4ed2423d9e63e71e4105cc22e6dbcb8bc4797612653f5c8cc38d1c9954c76229.2fa1917386056883053a04ed5d44adf1f1dc1cd20881a810ffb522ef3c47cee2\n",
            "08/09/2021 08:10:34 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/4ed2423d9e63e71e4105cc22e6dbcb8bc4797612653f5c8cc38d1c9954c76229.2fa1917386056883053a04ed5d44adf1f1dc1cd20881a810ffb522ef3c47cee2\n",
            "08/09/2021 08:10:34 - INFO - filelock -   Lock 140265070802832 released on /root/.cache/torch/transformers/4ed2423d9e63e71e4105cc22e6dbcb8bc4797612653f5c8cc38d1c9954c76229.2fa1917386056883053a04ed5d44adf1f1dc1cd20881a810ffb522ef3c47cee2.lock\n",
            "08/09/2021 08:10:34 - INFO - transformers.modeling_utils -   loading weights file https://cdn.huggingface.co/jeniya/BERTOverflow/pytorch_model.bin from cache at /root/.cache/torch/transformers/4ed2423d9e63e71e4105cc22e6dbcb8bc4797612653f5c8cc38d1c9954c76229.2fa1917386056883053a04ed5d44adf1f1dc1cd20881a810ffb522ef3c47cee2\n",
            "08/09/2021 08:10:38 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/jeniya/BERTOverflow/config.json from cache at /root/.cache/torch/transformers/142616a02e9dc91c33dea71980a0b0a30293e9148a24200461db5a9a1d14cc08.9989c9b6c815ffeeb8371cbf069c97e290c68345d13de5c494dd0cc8378bb6a2\n",
            "08/09/2021 08:10:38 - INFO - transformers.tokenization_utils -   Model name 'jeniya/BERTOverflow' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'jeniya/BERTOverflow' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
            "08/09/2021 08:10:39 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/jeniya/BERTOverflow/vocab.txt from cache at /root/.cache/torch/transformers/366ae98d80f3b62a08f76a38479c158b649841fd881ff16b7743c6cd02e631bc.57407c8df6c9d1057e13023df5979b60098b4ddabccd9eaa0bb483a48778f8ff\n",
            "08/09/2021 08:10:39 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/jeniya/BERTOverflow/added_tokens.json from cache at None\n",
            "08/09/2021 08:10:39 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/jeniya/BERTOverflow/special_tokens_map.json from cache at /root/.cache/torch/transformers/a48a990c12709e78145491ae4164de040c423ba56ad84bb065c5b790b70e979c.1f04d662a14dbb60dcf1073d308fd370f7244f21fee819dd5627fb5afeb761b1\n",
            "08/09/2021 08:10:39 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/jeniya/BERTOverflow/tokenizer_config.json from cache at /root/.cache/torch/transformers/584c0fa64a417a840bbf15614dc921abe67c1a1ad7b24a4e286384304d047dfc.6d3e4821752052e0ae3af7835326d4262263e6de3587c25295702a3dc40ba072\n",
            "08/09/2021 08:10:40 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/jeniya/BERTOverflow/config.json from cache at /root/.cache/torch/transformers/142616a02e9dc91c33dea71980a0b0a30293e9148a24200461db5a9a1d14cc08.9989c9b6c815ffeeb8371cbf069c97e290c68345d13de5c494dd0cc8378bb6a2\n",
            "08/09/2021 08:10:40 - INFO - transformers.modeling_utils -   loading weights file https://cdn.huggingface.co/jeniya/BERTOverflow/pytorch_model.bin from cache at /root/.cache/torch/transformers/4ed2423d9e63e71e4105cc22e6dbcb8bc4797612653f5c8cc38d1c9954c76229.2fa1917386056883053a04ed5d44adf1f1dc1cd20881a810ffb522ef3c47cee2\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}